{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Final Exam, Spring 2022: March (through May) Madness\n",
    "_Version 1.0_\n",
    "\n",
    "*All of the header information is important. Please read it..*\n",
    "\n",
    "**Topics, number of exercises:** This problem builds on your knowledge of Pandas, SQL, and numeric computation. It has 9 exercises, numbered 0 to 8. There are **19** available points. However, to earn 100% the threshold is **12** points. (Therefore, once you hit **12** points, you can stop. There is no extra credit for exceeding this threshold.)\n",
    "\n",
    "**Exercise ordering:** Each exercise builds logically on previous exercises, but you may solve them in any order. That is, if you can't solve an exercise, you can still move on and try the next one. Use this to your advantage, as the exercises are **not** necessarily ordered in terms of difficulty. Higher point values generally indicate more difficult exercises. \n",
    "\n",
    "**Demo cells:** Code cells starting with the comment `### define demo inputs` load results from prior exercises applied to the entire data set and use those to build demo inputs. These must be run for subsequent demos to work properly, but they do not affect the test cells. The data loaded in these cells may be rather large (at least in terms of human readability). You are free to print or otherwise use Python to explore them, but we did not print them in the starter code.\n",
    "\n",
    "**Debugging you code:** Right before each exercise test cell, there is a block of text explaining the variables available to you for debugging. You may use these to test your code and can print/display them as needed (careful when printing large objects, you may want to print the head or chunks of rows at a time).\n",
    "\n",
    "**Exercise point breakdown:**\n",
    "\n",
    "- Exercise 0: 1 point \n",
    "- Exercise 1: 3 point  \n",
    "- Exercise 2: 1 point  \n",
    "- Exercise 3: 3 point  \n",
    "- Exercise 4: 2 point  \n",
    "- Exercise 5: 3 point\n",
    "- Exercise 6: 3 point\n",
    "- Exercise 7: 1 point\n",
    "- Exercise 8: 2 point\n",
    "\n",
    "**Final reminders:** \n",
    "\n",
    "- Submit after **every exercise**\n",
    "- Review the generated grade report after you submit to see what errors were returned\n",
    "- Stay calm, skip problems as needed, and take short breaks at your leisure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Basketball basics\n",
    "\n",
    "\n",
    "In this notebook we want to predict which team will win a basketball game based on their past performance in a given season. You do not have to know anything about basketball aside from the background below to complete this notebook.\n",
    "\n",
    "- **Games.** A basketball game is played between two teams.\n",
    "- In most games, there is a \"home\" team and an \"away\" team. However sometimes games are played at a neutral site, in which case neither team is \"home\" nor \"away.\"\n",
    "- **Scoring and winning.** In a game, the team that scores more points wins. There are no ties.\n",
    "- **Possessions.** A possession is an event where one team continuously controls the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "conn = sqlite3.connect('resource/asnlib/publicdata/basketball_db.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 0 - (1 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex0"
    ]
   },
   "source": [
    "We have a big collection of real data from several seasons of men's NCAA basketball. We are most interested in one table of this database, named `MRegularSeasonDetailedResults`.\n",
    "\n",
    "\n",
    "Complete the function `get_cols(conn)` to return a `list` of the columns in the `MRegularSeasonDetailedResults` table in the db connection `conn`. The order of the columns in the list should be the same as the order they appear in the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "tags": [
     "exercise_solution_ex0"
    ]
   },
   "outputs": [],
   "source": [
    "### Define get_cols\n",
    "def get_cols(conn):\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"PRAGMA table_info(MRegularSeasonDetailedResults)\")\n",
    "    columns = [column[1] for column in cursor.fetchall()]\n",
    "    return columns\n",
    "\n",
    "\n",
    "#     sql_cmd=\"\"\"\n",
    "#     SELECT * FROM MRegularSeasonDetailedResults\n",
    "#     LIMIT 1;\n",
    "#     \"\"\"\n",
    "#     df = pd.read_sql_query(sql_cmd,conn)\n",
    "#     ###\n",
    "#     return list(df.columns)\n",
    "\n",
    "\n",
    "# return pd.read_sql('''select * from MRegularSeasonDetailedResults limit 1''', conn)\\\n",
    "#         .columns\\\n",
    "#         .tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex0"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "['index', 'Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc', 'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']\n"
     ]
    }
   ],
   "source": [
    "### call demo funtion\n",
    "print(get_cols(conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 0. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex0",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex0\n",
    "from tester_fw.testers import Tester_ex0\n",
    "tester = Tester_ex0()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_cols)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Abriged data dictionary\n",
    "In the `MRegularSeasonDetailedResults` table, each record is one game. All columns prefixed by 'W' refer to the winning team, and columns prefixed by 'L' refer to the losing team. We are primarily interested in the following columns:\n",
    "\n",
    "|Column|Type|Has Prefix|Description|\n",
    "|------|----|----------|-----------|\n",
    "|Season|Integer|No|Identifies the calendar year when a season ends.|\n",
    "|DayNum|Integer|No|Identifies the day in a season when a game occurred. |\n",
    "|TeamID|Integer|W or L|Identifies the teams participating in a game.|\n",
    "|Score|Integer|W or L|Number of points a team scored in a game.|\n",
    "|Loc|Char|W Only|Identifies whether the winning team was home ('H'), away ('A'), or the game was played at a neutral site ('N').|\n",
    "|FGA|Integer|W or L|Number of field goal attempts occurring when a team had in a game|\n",
    "|FTA|Integer|W or L|Number of free throw attempts a team had in a game.|\n",
    "|TO|Integer|W or L|Number of turnovers a team had in a game. |\n",
    "|OR|Integer|W or L|Number of offensive rebounds a team had in a game.|\n",
    "\n",
    "For example, the column with the winning team's ID will be WTeamID, and the column with the losing team's free-throw attempts will be LFTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1 - (3 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex1"
    ]
   },
   "source": [
    "We want to extract some information about each team involved in a game from that team's perspective. **We will use the term \"primary team\" to refer to this team and \"primary team's opponent\" to refer to the other team in the game. Do not infer any other meaning from this term.** Since there are two participants in each game there will be a record from the perspective of **both teams** after the extraction. (i.e. one record where the winning team is the primary team and one record where the losing team is the primary team will be in the result.\n",
    "\n",
    "Complete the function `get_pace_adjusted(conn)` to query the table `MRegularSeasonDetailedResults` using the db connection `conn` and return a Pandas DataFrame with the columns outlined below. The \"Winning Team\" and \"Losing Team\" headers in the chart below indicate which columns in `MRegularSeasonDetailedResults` to use in your computations.\n",
    "\n",
    "|Column Name|dtype|description|Special Considerations|Winning Team|Losing Team|\n",
    "|-|-|-|-|\n",
    "|Won           |     int64|1 if the primary team won the game, 0 if the primary team lost||1|0\n",
    "|Season        |     int64|Current `Season` ||\n",
    "|DayNum        |     int64|Current `DayNum` ||\n",
    "|TeamID        |     int64|Team id for primary team||WTeamID|LTeamID\n",
    "|OppID         |     int64|Team id for primary team's opponent||LTeamID|WTeamID\n",
    "|Home          |     int64|1 if the primary team is at home for the game, 0 otherwise.||`WLoc` is 'H'|`WLoc` is 'A'\n",
    "|Pos           |   float64|Estimated number of possessions for primary team|Round to 5 decimal places|`W` prefix|`L` prefix\n",
    "|OppPos        |   float64|Estimated number of possessions for primary team's opponent|Round to 5 decimal places|`L` prefix|`W` prefix\n",
    "|PtsForPer100  |   float64|100 $\\times$ primary team's score $\\div$ estimate of primary team's possessions|Round to 5 decimal places (only round after division)|`W` prefix|`L` prefix\n",
    "|PtsAgstPer100 |   float64|100 $\\times$ primary team's opponent's score $\\div$ estimate of primary team's opponent's possessions|Round to 5 decimal places (only round after division)|`L` prefix|`W` prefix\n",
    "\n",
    "\n",
    "There is no column for possessions in our source data. We will need to estimate it! The formula below is widely used in sports analytics to estimate the number of possessions a team had in a basketball game. ($POS$ is # of possessions):\n",
    "\n",
    "$POS$ = $FGA$ + 0.44($FTA$) + $TO$ - $OR$\n",
    "\n",
    "You can derive all required results from these columns: `Season, DayNum, WTeamID, WScore, LTeamID, LScore, WLoc, WFGA, WFTA, WOR, WTO, LFGA, LFTA, LOR, LTO`.\n",
    "\n",
    "**Notes:** \n",
    "- Each record in the database table `MRegularSeasonDetailedResults` will correspond to **two** records in the result. One record where the winning team is the primary team and one record where the losing team is the primary team.\n",
    "- For neutral site games, neither team will be home or away. The `WLoc` column will have an `'N'` entry.\n",
    "- The columns should be in the **exact** order given above, but the records can be sorted any way you like.\n",
    "- The `dtypes` attribute of your result must match **exactly**.\n",
    "- This question can be answered using either SQL or Pandas.\n",
    "  - The `UNION ALL` phrase may be helpful if you are using SQL.\n",
    "  - The `pd.concat()` method may be helpful if you are using Pandas.\n",
    "- One strategy that will work is making a table/df for all the winning teams and another for all the losing teams then vertically \"stacking\" them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "tags": [
     "exercise_solution_ex1"
    ]
   },
   "outputs": [],
   "source": [
    "### Define get_pace_adjusted\n",
    "def get_pace_adjusted(conn):\n",
    "    \n",
    "    query = '''\n",
    "    SELECT \n",
    "        1 AS Won,\n",
    "        Season, \n",
    "        DayNum, \n",
    "        WTeamID AS TeamID, \n",
    "        LTeamID AS OppID, \n",
    "        CASE \n",
    "            WHEN WLoc='H' THEN 1 \n",
    "            ELSE 0 \n",
    "        END AS Home, \n",
    "        ROUND((WFGA + 0.44 * WFTA + WTO - WOR), 5) AS Pos, \n",
    "        ROUND((LFGA + 0.44 * LFTA + LTO - LOR), 5) AS OppPos, \n",
    "        ROUND((100 * WScore / (WFGA + 0.44 * WFTA + WTO - WOR)), 5) AS PtsForPer100, \n",
    "        ROUND((100 * LScore / (LFGA + 0.44 * LFTA + LTO - LOR)), 5) AS PtsAgstPer100 \n",
    "    FROM \n",
    "        MRegularSeasonDetailedResults \n",
    "    UNION ALL \n",
    "    SELECT \n",
    "        0 AS Won, \n",
    "        Season, \n",
    "        DayNum, \n",
    "        LTeamID AS TeamID, \n",
    "        WTeamID AS OppID, \n",
    "        CASE \n",
    "            WHEN WLoc='A' THEN 1 \n",
    "            ELSE 0 \n",
    "        END AS Home, \n",
    "        ROUND((LFGA + 0.44 * LFTA + LTO - LOR), 5) AS Pos, \n",
    "        ROUND((WFGA + 0.44 * WFTA + WTO - WOR), 5) AS OppPos, \n",
    "        ROUND((100 * LScore / (LFGA + 0.44 * LFTA + LTO - LOR)), 5) AS PtsForPer100, \n",
    "        ROUND((100 * WScore / (WFGA + 0.44 * WFTA + WTO - WOR)), 5) AS PtsAgstPer100 \n",
    "    FROM \n",
    "        MRegularSeasonDetailedResults\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#     sql_cmd=\"\"\"\n",
    "#     SELECT * FROM MRegularSeasonDetailedResults;\n",
    "#     \"\"\"\n",
    "#     df = pd.read_sql_query(sql_cmd,conn)\n",
    "#     # for win games\n",
    "#     win_games = df.copy().rename(columns={\"WTeamID\":\"TeamID\",\"LTeamID\":\"OppID\"})\n",
    "#     win_games[\"Home\"] = (win_games[\"WLoc\"]==\"H\").astype(int)\n",
    "#     win_games[\"Won\"] = 1\n",
    "#     win_games[\"Pos\"] = win_games[\"WFGA\"] + (0.44 * win_games[\"WFTA\"]) + win_games[\"WTO\"] - win_games[\"WOR\"]\n",
    "#     win_games[\"OppPos\"] = win_games[\"LFGA\"] + (0.44 * win_games[\"LFTA\"]) + win_games[\"LTO\"] - win_games[\"LOR\"]\n",
    "#     win_games[\"PtsForPer100\"] = round(100.0*win_games[\"WScore\"]/win_games[\"Pos\"],5)\n",
    "#     win_games[\"PtsAgstPer100\"] = round(100.0*win_games[\"LScore\"]/win_games[\"OppPos\"],5)\n",
    "#     win_games[\"Pos\"] = round(win_games[\"Pos\"],5)\n",
    "#     win_games[\"OppPos\"] = round(win_games[\"OppPos\"],5)\n",
    "#     col_list = [\"Won\", \"Season\", \"DayNum\" , \"TeamID\", \"OppID\",\"Home\", \"Pos\", \"OppPos\", \"PtsForPer100\", \"PtsAgstPer100\"]\n",
    "#     win_games = win_games[col_list]\n",
    "#     # for lost games\n",
    "#     lost_games = df.copy().rename(columns={\"LTeamID\":\"TeamID\",\"WTeamID\":\"OppID\"})\n",
    "#     lost_games[\"Home\"] = (lost_games[\"WLoc\"]==\"A\").astype(int)\n",
    "#     lost_games[\"Won\"] = 0\n",
    "#     lost_games[\"Pos\"] = lost_games[\"LFGA\"] + (0.44 * lost_games[\"LFTA\"]) + lost_games[\"LTO\"] - lost_games[\"LOR\"]\n",
    "#     lost_games[\"OppPos\"] = lost_games[\"WFGA\"] + (0.44 * lost_games[\"WFTA\"]) + lost_games[\"WTO\"] - lost_games[\"WOR\"]\n",
    "#     lost_games[\"PtsForPer100\"] = round(100.0*lost_games[\"LScore\"]/lost_games[\"Pos\"],5)\n",
    "#     lost_games[\"PtsAgstPer100\"] = round(100.0*lost_games[\"WScore\"]/lost_games[\"OppPos\"],5)\n",
    "#     lost_games[\"Pos\"] = round(lost_games[\"Pos\"],5)\n",
    "#     lost_games[\"OppPos\"] = round(lost_games[\"OppPos\"],5)\n",
    "#     col_list = [\"Won\", \"Season\", \"DayNum\" , \"TeamID\", \"OppID\",\"Home\", \"Pos\", \"OppPos\", \"PtsForPer100\", \"PtsAgstPer100\"]\n",
    "#     lost_games = lost_games[col_list]\n",
    "#     return pd.concat([win_games,lost_games])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex1"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "This is the demo input:\n",
    "```\n",
    "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  WFGA  WFTA  WOR  WTO  LFGA  LFTA  LOR  LTO \n",
    "0    2003      10     1104      68     1328      62    N    58    18   14   23    53    22   10   18\n",
    "```\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "      Won  Season  DayNum  TeamID  OppID  Home    Pos  OppPos  PtsForPer100     PtsAgstPer100  \n",
    "   0    1    2003      10    1104   1328     0  74.92   70.68      90.76348          87.71930\n",
    "   1    0    2003      10    1328   1104     0  70.68   74.92      87.71930          90.76348\n",
    "\n",
    "```\n",
    "Note that there are two rows, but they come from a single input row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_inputs_ex1"
    ]
   },
   "outputs": [],
   "source": [
    "### define demo inputs\n",
    "from tester_fw.test_utils import dfs_to_conn\n",
    "demo_df_1 = pd.read_sql('select Season, DayNum, WTeamID, WScore, LTeamID, LScore, WLoc, WFGA, WFTA, WOR, WTO, LFGA, LFTA, LOR, LTO from MRegularSeasonDetailedResults limit 1', conn)\n",
    "demo_conn_1 = dfs_to_conn({'MRegularSeasonDetailedResults': demo_df_1})\n",
    "# demo_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Won  Season  DayNum  TeamID  OppID  Home    Pos  OppPos  PtsForPer100  \\\n",
      "0    1    2003      10    1104   1328     0  74.92   70.68      90.76348   \n",
      "1    0    2003      10    1328   1104     0  70.68   74.92      87.71930   \n",
      "\n",
      "   PtsAgstPer100  \n",
      "0       87.71930  \n",
      "1       90.76348  \n"
     ]
    }
   ],
   "source": [
    "### call demo funtion\n",
    "print(get_pace_adjusted(demo_conn_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 1. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex1\n",
    "from tester_fw.testers import Tester_ex1\n",
    "tester = Tester_ex1()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_pace_adjusted)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2 - (1 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex2"
    ]
   },
   "source": [
    "Our next task is to compute daily totals of `Pos`, `OppPos`, `PtsForPer100`, and `PtsAgstPer100` as well as a count of the number of teams participating in games that day.\n",
    "\n",
    "Complete the function `daily_totals(conn)` to query the table `PaceAdjusted` (structured the same as the output of the previous exercise) in the db connection `conn` and return a Pandas DataFrame with the following columns:\n",
    "\n",
    "|Column Name|dtype|description|\n",
    "|-|-|-|\n",
    "|Season|int64||\n",
    "|DayNum|int64||\n",
    "|Pos|float64|Sum of values in `Pos` column of `PaceAdjusted` occuring on a unique combination of `Season` and `DayNum`|\n",
    "|Pph|float64|Sum of values in `PtsForPer100` column of `PaceAdjusted` occuring on a unique combination of `Season` and `DayNum`|\n",
    "|Count|int64|Count of rows in `PaceAdjusted` with a unique combination of `Season` and `DayNum`|\n",
    "\n",
    "**Notes:** \n",
    "- The columns should be in the **exact** order given above, but the records can be sorted any way you like.\n",
    "- The `dtypes` attribute of your result must match **exactly**.\n",
    "- This question can be answered using either SQL or Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "tags": [
     "exercise_solution_ex2"
    ]
   },
   "outputs": [],
   "source": [
    "### Define daily_totals\n",
    "def daily_totals(conn):\n",
    "    \n",
    "    query = '''\n",
    "    SELECT Season, DayNum, SUM(Pos) AS Pos, SUM(PtsForPer100) AS Pph, COUNT(*) AS Count\n",
    "    FROM PaceAdjusted \n",
    "    GROUP BY Season, DayNum\n",
    "    ORDER BY Season, DayNum\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#     pace_adj_df = pd.read_sql_query(\"SELECT * FROM PaceAdjusted\",conn)\n",
    "#     res = pace_adj_df.groupby([\"Season\",\"DayNum\"]).agg({\"Pos\":sum,\"PtsForPer100\":sum,\"TeamID\":\"count\"}).reset_index()\n",
    "#     res = res.rename(columns={\"PtsForPer100\":\"Pph\",\"TeamID\":\"Count\"})\n",
    "#     res = res[[\"Season\",\"DayNum\",\"Pos\",\"Pph\",\"Count\"]]\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex2"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "   Season  DayNum     Pos        Pph  Count\n",
    "0    2010      94  277.28  433.33581      4\n",
    "1    2010     108  281.64  415.62023      4\n",
    "2    2010     122  265.88  395.26418      4\n",
    "3    2016      49  365.04  467.93858      5\n",
    "4    2016     115  204.08  309.66380      3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_inputs_ex2"
    ]
   },
   "outputs": [],
   "source": [
    "### define demo inputs\n",
    "from tester_fw.test_utils import dfs_to_conn\n",
    "demo_df_2 = pd.read_sql('select * from PaceAdjustedSample', conn)\n",
    "demo_conn_2 = dfs_to_conn({'PaceAdjusted': demo_df_2})\n",
    "# demo_df_2.sort_values(['Season', 'DayNum']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  DayNum     Pos        Pph  Count\n",
      "0    2010      94  277.28  433.33581      4\n",
      "1    2010     108  281.64  415.62023      4\n",
      "2    2010     122  265.88  395.26418      4\n",
      "3    2016      49  365.04  467.93858      5\n",
      "4    2016     115  204.08  309.66380      3\n"
     ]
    }
   ],
   "source": [
    "### call demo funtion\n",
    "print(daily_totals(demo_conn_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 2. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex2",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex2\n",
    "from tester_fw.testers import Tester_ex2\n",
    "tester = Tester_ex2()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(daily_totals)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## On Window Functions...\n",
    "**This is useful information**\n",
    "\n",
    "Window functions define a slice of data relative to each row in a dataset and then perform an aggregate or order-based calculation on the slice. For example, say you want to perform the following calculation for each row $i$ in `DailyTotals`:\n",
    "\n",
    "`SumPos`$_i$ $:=$ Sum of the `Pos` column for all rows where `Season` = `Season`$_i$ and `DayNum` $\\le$ `DayNum`$_i$\n",
    "\n",
    "Window functions can do this. Below are examples of this computation in Pandas and SQL. First, we will load some data to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# define demo data\n",
    "from tester_fw.test_utils import dfs_to_conn\n",
    "demo_conn_dfs_ex3 = {}\n",
    "demo_conn_dfs_ex3['DailyTotals'] = pd.read_sql('select * from DailyTotalsSample', conn)\n",
    "demo_conn_ex3 = dfs_to_conn(demo_conn_dfs_ex3)\n",
    "daily_totals_df = demo_conn_dfs_ex3['DailyTotals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The code below will return the sample data with a new column \"SumPos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Pandas Example\n",
    "def pandas_window_helper(group):\n",
    "    group = group.sort_values('DayNum')\n",
    "    group['SumPos'] = group['Pos'].expanding(1).sum()\n",
    "    return group\n",
    "pandas_ex = daily_totals_df.groupby('Season', as_index=False).apply(pandas_window_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The code below will return the sample data with a new column \"SumPos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### SQL Example\n",
    "query = '''\n",
    "    SELECT \n",
    "        *,\n",
    "        SUM(pos) OVER(PARTITION BY Season ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as SumPos\n",
    "    FROM\n",
    "        DailyTotals\n",
    "    ORDER BY\n",
    "        Season, DayNum\n",
    "'''\n",
    "sql_ex = pd.read_sql(query, demo_conn_ex3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The code below will print the result and verify that the two approaches give equivalent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Pph</th>\n",
       "      <th>Count</th>\n",
       "      <th>SumPos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>8725.84</td>\n",
       "      <td>13482.43561</td>\n",
       "      <td>128</td>\n",
       "      <td>8725.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>15</td>\n",
       "      <td>6146.96</td>\n",
       "      <td>9299.04948</td>\n",
       "      <td>88</td>\n",
       "      <td>14872.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>18</td>\n",
       "      <td>7301.64</td>\n",
       "      <td>11764.86247</td>\n",
       "      <td>108</td>\n",
       "      <td>22174.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>41</td>\n",
       "      <td>4452.52</td>\n",
       "      <td>6702.86892</td>\n",
       "      <td>66</td>\n",
       "      <td>26626.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>44</td>\n",
       "      <td>5381.96</td>\n",
       "      <td>8625.92495</td>\n",
       "      <td>82</td>\n",
       "      <td>32008.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014</td>\n",
       "      <td>59</td>\n",
       "      <td>8673.96</td>\n",
       "      <td>13265.97248</td>\n",
       "      <td>128</td>\n",
       "      <td>40682.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>102</td>\n",
       "      <td>1400.72</td>\n",
       "      <td>2062.01746</td>\n",
       "      <td>20</td>\n",
       "      <td>42083.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>127</td>\n",
       "      <td>1696.20</td>\n",
       "      <td>2684.90264</td>\n",
       "      <td>26</td>\n",
       "      <td>43779.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>29</td>\n",
       "      <td>4150.56</td>\n",
       "      <td>5600.57650</td>\n",
       "      <td>58</td>\n",
       "      <td>4150.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021</td>\n",
       "      <td>96</td>\n",
       "      <td>13485.76</td>\n",
       "      <td>19887.61275</td>\n",
       "      <td>194</td>\n",
       "      <td>17636.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum       Pos          Pph  Count    SumPos\n",
       "0    2014      12   8725.84  13482.43561    128   8725.84\n",
       "1    2014      15   6146.96   9299.04948     88  14872.80\n",
       "2    2014      18   7301.64  11764.86247    108  22174.44\n",
       "3    2014      41   4452.52   6702.86892     66  26626.96\n",
       "4    2014      44   5381.96   8625.92495     82  32008.92\n",
       "5    2014      59   8673.96  13265.97248    128  40682.88\n",
       "6    2014     102   1400.72   2062.01746     20  42083.60\n",
       "7    2014     127   1696.20   2684.90264     26  43779.80\n",
       "8    2021      29   4150.56   5600.57650     58   4150.56\n",
       "9    2021      96  13485.76  19887.61275    194  17636.32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL and Pandas results match? True\n"
     ]
    }
   ],
   "source": [
    "display(sql_ex)\n",
    "print(f'''SQL and Pandas results match? {\n",
    "((sql_ex.reset_index(drop=True) - pandas_ex.reset_index(drop=True)).abs() <= 0.00001).all().all()}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3 - (3 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex3"
    ]
   },
   "source": [
    "<!-- Exercise text block -->\n",
    "Our next task is to compute the weighted running average for `Pos` and `Pph` for all games played in a `Season` up to and including each `DayNum`. We want a snapshot of these averages as if it were that particular day and we had no knowledge of events occurring after that day.\n",
    "\n",
    "Complete the function `get_running_avg_pace(conn)` to query the table `DailyTotals` (structured the same as the output of the previous exercise) using the db connection `conn` and return a Pandas DataFrame with the columns mentioned below. You should calculate the intermediate values then use division to get the end result.\n",
    "\n",
    "**Intermediate values**\n",
    "- `SumPos` - Running sum of the \"Pos\" column for current \"Season\" up to and including the current \"DayNum\".\n",
    "- `SumPph` - Running sum of the \"Pph\" column for current \"Season\" up to and including the current \"DayNum\".\n",
    "- `SumCount` - Running sum of the \"Count\" column for current \"Season\" up to and including the current \"DayNum\".\n",
    "\n",
    "|Column Name|dtype|description|Special Considerations|\n",
    "|-|-|-|-|\n",
    "|Season|       int64|Current `Season` | |\n",
    "|DayNum |      int64|Current `DayNum` | |\n",
    "|AvgPace |   float64|`SumPos` $\\div$ `SumCount`| Round to 5 decimal places|\n",
    "|AvgPPH   |  float64|`SumPph` $\\div$ `SumCount`| Round to 5 decimal places|\n",
    "\n",
    "**Notes:**\n",
    "- The columns should be in the **exact** order given above, but the records can be sorted any way you like.\n",
    "- The `dtypes` attribute of your result must match **exactly**.\n",
    "- This question can be answered using either SQL or Pandas.\n",
    "  - See \"On Window Functions...\" above this exercise for more info on computing a running sum.\n",
    "  - For Pandas `pd.DataFrame.groupby().apply()` and `pd.Series.expanding()` may be useful in calculating intermediate values.\n",
    "  - For SQL the \"window function\" syntax may be useful in calculating intermediate values.\n",
    "    - `SUM(...) OVER(PARTITION BY ... ORDER BY ... ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "tags": [
     "exercise_solution_ex3"
    ]
   },
   "outputs": [],
   "source": [
    "### Define def get_running_avg_pace\n",
    "def get_running_avg_pace(conn):\n",
    "    \n",
    "    query = '''\n",
    "    SELECT Season, DayNum, \n",
    "    ROUND(((SUM(Pos) OVER(PARTITION BY Season ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW))/\\\n",
    "    (SUM(Count) OVER(PARTITION BY Season ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW))),5) \\\n",
    "    AS AvgPace,\n",
    "    ROUND(((SUM(Pph) OVER(PARTITION BY Season ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW))/\\\n",
    "    (SUM(Count) OVER(PARTITION BY Season ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW))),5) \\\n",
    "    AS AvgPPH\n",
    "    FROM DailyTotals\n",
    "    ORDER BY\n",
    "        Season, DayNum\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_sql(query, conn)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "#      def window_helper(agg_col, partition_col, sort_col):\n",
    "#         return f'SUM({agg_col}) OVER(PARTITION BY {partition_col} ORDER BY {sort_col} ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)'\n",
    "# #     return window_helper('Pos', 'Season', 'DayNum')\n",
    "#     intermediate_result = pd.read_sql(f'''\n",
    "#     select\n",
    "#         Season, DayNum,\n",
    "#         {window_helper('Pos', 'Season', 'DayNum')} SumPos,\n",
    "#         {window_helper('Pph', 'Season', 'DayNum')} SumPph,\n",
    "#         {window_helper('Count', 'Season', 'DayNum')} SumCount\n",
    "#     from \n",
    "#         DailyTotals\n",
    "#     ''', conn)\n",
    "#     df = intermediate_result\n",
    "#     df['AvgPace'] = df['SumPos'] / df['SumCount']\n",
    "#     df['AvgPPH'] = df['SumPph'] / df['SumCount']\n",
    "#     return df.drop(columns=['SumPos', 'SumPph', 'SumCount'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex3"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "   Season  DayNum   AvgPace     AvgPPH\n",
    "0    2014      12  68.17063  105.33153\n",
    "1    2014      15  68.85556  105.46984\n",
    "2    2014      18  68.43963  106.62453\n",
    "3    2014      41  68.27426  105.76722\n",
    "4    2014      44  67.81551  105.66767\n",
    "5    2014      59  67.80480  105.23519\n",
    "6    2014     102  67.87677  105.16634\n",
    "7    2014     127  67.77059  105.08984\n",
    "8    2021      29  71.56138   96.56166\n",
    "9    2021      96  69.98540  101.14361\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_inputs_ex3"
    ]
   },
   "outputs": [],
   "source": [
    "### define demo inputs\n",
    "from tester_fw.test_utils import dfs_to_conn\n",
    "demo_conn_dfs_ex3 = {}\n",
    "demo_conn_dfs_ex3['DailyTotals'] = pd.read_sql('select * from DailyTotalsSample', conn)\n",
    "demo_conn_ex3 = dfs_to_conn(demo_conn_dfs_ex3)\n",
    "# demo_conn_dfs_ex3['DailyTotals'].sort_values(['Season', 'DayNum']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  DayNum   AvgPace     AvgPPH\n",
      "0    2014      12  68.17063  105.33153\n",
      "1    2014      15  68.85556  105.46984\n",
      "2    2014      18  68.43963  106.62453\n",
      "3    2014      41  68.27426  105.76722\n",
      "4    2014      44  67.81551  105.66767\n",
      "5    2014      59  67.80480  105.23519\n",
      "6    2014     102  67.87677  105.16634\n",
      "7    2014     127  67.77059  105.08984\n",
      "8    2021      29  71.56138   96.56166\n",
      "9    2021      96  69.98540  101.14361\n"
     ]
    }
   ],
   "source": [
    "### call demo funtion\n",
    "print(get_running_avg_pace(demo_conn_ex3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 3. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex3",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex3\n",
    "from tester_fw.testers import Tester_ex3\n",
    "tester = Tester_ex3()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_running_avg_pace)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 4 - (2 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex4"
    ]
   },
   "source": [
    "Suppose you are given two SQL tables:\n",
    "1. `PaceAdjusted`, structured the same as the output of Exercise 1.\n",
    "2. `RunningAvgPace`, structured the same as the output of Exercise 3.\n",
    "\n",
    "Complete the function `get_center_pace_adjusted(conn)` to query tables `RunningAvgPace`  and `PaceAdjusted`  and return a Pandas DataFrame with the following columns:\n",
    "\n",
    "|Column Name|dtype|description|\n",
    "|-|-|-|\n",
    "|Won    |            int64|Unchanged from `PaceAdjusted`|\n",
    "|Season     |        int64|Unchanged from `PaceAdjusted`|\n",
    "|DayNum   |          int64|Unchanged from `PaceAdjusted`|\n",
    "|TeamID   |          int64|Unchanged from `PaceAdjusted`|\n",
    "|OppID   |           int64|Unchanged from `PaceAdjusted`|\n",
    "|Home     |          int64|Unchanged from `PaceAdjusted`|\n",
    "|Pos       |       float64|`PaceAdjusted.Pos` - `RunningAvgPace.AvgPace` for corresponding `Season` and `DayNum`|\n",
    "|OppPos        |   float64|`PaceAdjusted.OppPos` - `RunningAvgPace.AvgPace` for corresponding `Season` and `DayNum`|\n",
    "|PtsAgstPer100  |  float64|`PaceAdjusted.PtsAgstPer100` - `RunningAvgPace.AvgPPH` for corresponding `Season` and `DayNum`|\n",
    "|PtsForPer100  |   float64|`PaceAdjusted.PtsForPer100` - `RunningAvgPace.AvgPPH` for corresponding `Season` and `DayNum`|\n",
    "\n",
    "**Notes:**\n",
    "- The columns should be in the **exact** order given above, but the records can be sorted any way you like.\n",
    "- The `dtypes` attribute of your result must match **exactly**.\n",
    "- This question can be answered using either SQL or Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "tags": [
     "exercise_solution_ex4"
    ]
   },
   "outputs": [],
   "source": [
    "### Define get_center_pace_adjusted\n",
    "def get_center_pace_adjusted(conn):\n",
    "    \n",
    "    query='''   \n",
    "    \n",
    "    SELECT PA.Won, PA.Season, PA.DayNum, PA.TeamID, PA.OppID, PA.Home,\\\n",
    "    (PA.Pos-RA.AvgPace) AS Pos, (PA.OppPos-RA.AvgPace) AS OppPos, (PA.PtsAgstPer100 - RA.AvgPPH) AS PtsAgstPer100,\\\n",
    "    (PA.PtsForPer100 - RA.AvgPPH)AS PtsForPer100\n",
    "    FROM PaceAdjusted AS PA, RunningAvgPace AS RA\n",
    "    WHERE PA.Season = RA.Season and PA.DayNum = RA.DayNum\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    df = pd.read_sql(query, conn)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#     pace_adj = pd.read_sql_query(\"Select * FROM PaceAdjusted\",conn)\n",
    "#     run_avg_pace = pd.read_sql_query(\"Select * FROM RunningAvgPace\",conn)\n",
    "#     res = pace_adj.merge(run_avg_pace,on=[\"Season\",\"DayNum\"])\n",
    "#     res[\"Pos\"] = res[\"Pos\"] - res[\"AvgPace\"]\n",
    "#     res[\"OppPos\"] = res[\"OppPos\"] - res[\"AvgPace\"]\n",
    "#     res[\"PtsForPer100\"] = res[\"PtsForPer100\"] - res[\"AvgPPH\"]\n",
    "#     res[\"PtsAgstPer100\"] = res[\"PtsAgstPer100\"] - res[\"AvgPPH\"]\n",
    "#     return res[[\"Won\",\"Season\",\"DayNum\",\"TeamID\",\"OppID\",\"Home\",\"Pos\",\"OppPos\",\"PtsAgstPer100\",\"PtsForPer100\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex4"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "   Won  Season  DayNum  TeamID  OppID  Home       Pos    OppPos  \\\n",
    "0    1    2014      94    1374   1396     1  -3.86907  -2.18907   \n",
    "1    0    2016     119    1224   1313     0   2.65129   5.57129   \n",
    "2    0    2016      90    1353   1277     0   4.05371   2.13371   \n",
    "3    1    2016     119    1300   1366     1  -8.78871  -9.30871   \n",
    "4    1    2014      94    1383   1384     1  -2.30907  -4.66907   \n",
    "5    1    2014      94    1190   1297     0  -9.42907  -9.62907   \n",
    "6    0    2014      94    1223   1101     0   0.29093   0.69093   \n",
    "7    0    2014      94    1218   1364     1  -1.98907  -3.58907   \n",
    "8    0    2014      92    1159   1221     1 -13.28500 -12.96500   \n",
    "9    0    2014      81    1297   1252     1   1.52248   1.76248   \n",
    "\n",
    "   PtsAgstPer100  PtsForPer100  \n",
    "0      -25.32271      13.22592  \n",
    "1        7.78985     -12.71682  \n",
    "2       29.99420     -19.84044  \n",
    "3      -31.11146      -3.56274  \n",
    "4      -22.13333      14.99904  \n",
    "5      -18.41211       5.59099  \n",
    "6       22.95005      14.80074  \n",
    "7       12.70182      -7.11914  \n",
    "8       22.07960      20.97894  \n",
    "9        3.17351       2.09897  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_inputs_ex4"
    ]
   },
   "outputs": [],
   "source": [
    "### define demo inputs\n",
    "### use naming convention demo_varname_ex_* to name demo variables\n",
    "from tester_fw.test_utils import dfs_to_conn\n",
    "demo_conn_dfs_ex4 = {}\n",
    "demo_conn_dfs_ex4['PaceAdjusted'] = pd.read_sql('select * from PaceAdjustedSampleTwo', conn)\n",
    "demo_conn_dfs_ex4['RunningAvgPace'] = pd.read_sql('select * from RunningAvgPaceSample', conn)\n",
    "demo_conn_ex4 = dfs_to_conn(demo_conn_dfs_ex4)\n",
    "# print('PaceAdjusted')\n",
    "# display(demo_conn_dfs_ex4['PaceAdjusted'])\n",
    "# print('RunningAvgPace')\n",
    "# display(demo_conn_dfs_ex4['RunningAvgPace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex4"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Won  Season  DayNum  TeamID  OppID  Home       Pos    OppPos  \\\n",
      "0    1    2014      94    1374   1396     1  -3.86907  -2.18907   \n",
      "1    0    2016     119    1224   1313     0   2.65129   5.57129   \n",
      "2    0    2016      90    1353   1277     0   4.05371   2.13371   \n",
      "3    1    2016     119    1300   1366     1  -8.78871  -9.30871   \n",
      "4    1    2014      94    1383   1384     1  -2.30907  -4.66907   \n",
      "5    1    2014      94    1190   1297     0  -9.42907  -9.62907   \n",
      "6    0    2014      94    1223   1101     0   0.29093   0.69093   \n",
      "7    0    2014      94    1218   1364     1  -1.98907  -3.58907   \n",
      "8    0    2014      92    1159   1221     1 -13.28500 -12.96500   \n",
      "9    0    2014      81    1297   1252     1   1.52248   1.76248   \n",
      "\n",
      "   PtsAgstPer100  PtsForPer100  \n",
      "0      -25.32271      13.22592  \n",
      "1        7.78985     -12.71682  \n",
      "2       29.99420     -19.84044  \n",
      "3      -31.11146      -3.56274  \n",
      "4      -22.13333      14.99904  \n",
      "5      -18.41211       5.59099  \n",
      "6       22.95005      14.80074  \n",
      "7       12.70182      -7.11914  \n",
      "8       22.07960      20.97894  \n",
      "9        3.17351       2.09897  \n"
     ]
    }
   ],
   "source": [
    "### call demo funtion\n",
    "print(get_center_pace_adjusted(demo_conn_ex4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 4. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex4",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex4\n",
    "from tester_fw.testers import Tester_ex4\n",
    "tester = Tester_ex4()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_center_pace_adjusted)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 5 - (3 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex5"
    ]
   },
   "source": [
    "<!-- Exercise text block -->\n",
    "Now we have centered and pace adjusted stats for each Season, DayNum, and TeamID, it's time to compute running averages to set as inputs to our model. Since we are using these stats as inputs to a predictive model, we need to introduce a lag of 1 game so that the results of the game we are trying to predict are not part of these inputs.\n",
    "\n",
    "Complete the function `get_team_stats(conn)` to query the `PaceAdjustedCentered` (structured the same as the output of the previous exercise) table with the db connection `conn` and return a Pandas DataFrame with the following columns:\n",
    "\n",
    "|Column Name|dtype|description|Special Considerations|\n",
    "|-|-|-|-|\n",
    "|Won    |            int64||Unchanged from `PaceAdjustedCentered`|\n",
    "|Season  |           int64|Current Season|Unchanged from `PaceAdjustedCentered`|\n",
    "|DayNum   |          int64|Current Day|Unchanged from `PaceAdjustedCentered`|\n",
    "|TeamID    |         int64|Current TeamID|Unchanged from `PaceAdjustedCentered`\n",
    "|OppID      |       int64||Unchanged from `PaceAdjustedCentered`|\n",
    "|Home|int64||Unchanged from `PaceAdjustedCentered`|\n",
    "|Pos         |     float64|Running Average of `PaceAdjustedCentered.Pos` including all rows with the current `Season` and `TeamID` with `PaceAdjustedCentered.DayNum` < `DayNum`|Round to 5 decimal places|\n",
    "|OppPos       |    float64|Running Average of `PaceAdjustedCentered.OppPos` including all rows with the current `Season` and `TeamID` with `PaceAdjustedCentered.DayNum` < `DayNum`|Round to 5 decimal places|\n",
    "|PtsAgstPer100 |   float64|Running Average of `PaceAdjustedCentered.PtsAgstPer100` including all rows with the current `Season` and `TeamID` with `PaceAdjustedCentered.DayNum` < `DayNum`|Round to 5 decimal places|\n",
    "|PtsForPer100   |  float64|Running Average of `PaceAdjustedCentered.PtsForPer100` including all rows with the current `Season` and `TeamID` with `PaceAdjustedCentered.DayNum` < `DayNum`|Round to 5 decimal places|\n",
    "|WinPct          | float64|Running Average of `PaceAdjustedCentered.Won` including all rows with the current `Season` and `TeamID` with `DayNum` < `PaceAdjustedCentered.DayNum`|Round to 5 decimal places|\n",
    "\n",
    "**Notes:**\n",
    "- The columns should be in the **exact** order given above, but the records can be sorted any way you like.\n",
    "- The `dtypes` attribute of your result must match **exactly**.\n",
    "- This question can be answered using either SQL or Pandas.\n",
    "  - See \"On Window Functions...\" above Exercise 3 for more info on computing a running average.\n",
    "  - For Pandas `pd.DataFrame.groupby().apply()` and `pd.Series.expanding()` may be useful.\n",
    "  - For SQL the \"window function\" syntax may be useful.\n",
    "    - `AVG(...) OVER(PARTITION BY ... ORDER BY ... ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "tags": [
     "exercise_solution_ex5"
    ]
   },
   "outputs": [],
   "source": [
    "### Define get_team_stats\n",
    "def get_team_stats(conn):\n",
    "    \n",
    "    query = '''\n",
    "    SELECT Won, Season, DayNum, TeamID, OppID, Home,\n",
    "    ROUND((AVG(Pos)OVER(PARTITION BY Season, TeamID ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)),5) AS Pos,\n",
    "    ROUND((AVG(OppPos) OVER(PARTITION BY Season, TeamID ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)),5) AS OppPos,\n",
    "    ROUND((AVG(PtsAgstPer100) OVER(PARTITION BY Season, TeamID ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)),5) AS PtsAgstPer100,\n",
    "    ROUND((AVG(PtsForPer100) OVER(PARTITION BY Season, TeamID ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)),5) AS PtsForPer100,\n",
    "    ROUND((AVG(Won) OVER(PARTITION BY Season, TeamID ORDER BY DayNum ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)),5) AS WinPct\n",
    "    \n",
    "    FROM PaceAdjustedCentered \n",
    " \n",
    "    '''\n",
    "    \n",
    "    df = pd.read_sql(query, conn)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#     pace_adj_center = pd.read_sql_query(\"Select * FROM PaceAdjustedCentered\",conn)\n",
    "#     def pandas_window_helper_ad2(group):\n",
    "#         group = group.sort_values('DayNum')\n",
    "#         group['Pos'] = group['Pos'].shift(1).expanding(1).mean()\n",
    "#         group['OppPos'] = group['OppPos'].shift(1).expanding(1).mean()\n",
    "#         group['PtsAgstPer100'] = group['PtsAgstPer100'].shift(1).expanding(0).mean()\n",
    "#         group['PtsForPer100'] = group['PtsForPer100'].shift(1).expanding(0).mean()\n",
    "#         group['WinPct'] = group['Won'].shift(1).expanding(1).mean()\n",
    "#         return group\n",
    "#     res = pace_adj_center.groupby(['Season',\"TeamID\"], as_index = False).apply(pandas_window_helper_ad2)\n",
    "#     res = res[[\"Won\",\"Season\",\"DayNum\",\"TeamID\",\"OppID\",\"Home\",\"Pos\",\"OppPos\",\"PtsAgstPer100\",\"PtsForPer100\",\"WinPct\"\\\n",
    "#     ]].reset_index(drop=True)\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex5"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "    Won  Season  DayNum  TeamID  OppID  Home      Pos    OppPos  \\\n",
    "0     0    2012      17    1108   1452     0      NaN       NaN   \n",
    "1     0    2012      25    1108   1408     0  8.25697   8.53697   \n",
    "2     0    2012      26    1108   1360     0  5.65314   5.93314   \n",
    "3     1    2012     105    1108   1115     1  2.76368   2.09702   \n",
    "4     0    2012      16    1355   1208     0      NaN       NaN   \n",
    "5     1    2012      31    1355   1237     0 -5.81233  -5.33233   \n",
    "6     0    2012      45    1355   1315     0  5.07403   4.81403   \n",
    "7     1    2012     124    1355   1237     0  4.12049   4.84049   \n",
    "8     0    2012      29    1431   1332     0      NaN       NaN   \n",
    "9     1    2012      52    1431   1155     0 -4.58353  -5.26353   \n",
    "10    0    2012      72    1431   1409     0 -5.65785  -7.11785   \n",
    "11    1    2012      79    1431   1187     1 -6.81332  -8.17332   \n",
    "12    1    2012     103    1431   1408     1 -6.71588  -7.96588   \n",
    "13    1    2017      47    1252   1399     0      NaN       NaN   \n",
    "14    1    2017      50    1252   1122     0  9.78901  10.22901   \n",
    "15    1    2017      68    1252   1244     1  7.09400   8.63400   \n",
    "16    0    2017      82    1252   1316     0  6.62264   8.36930   \n",
    "17    1    2017      86    1252   1367     1  7.55313   8.32313   \n",
    "18    0    2017     108    1252   1316     1  6.32893   6.93693   \n",
    "19    0    2017     122    1252   1316     1  6.91365   7.39365   \n",
    "\n",
    "    PtsAgstPer100  PtsForPer100   WinPct  \n",
    "0             NaN           NaN      NaN  \n",
    "1        26.44115     -18.48766  0.00000  \n",
    "2        21.51181     -30.28407  0.00000  \n",
    "3        16.34005     -20.09929  0.00000  \n",
    "4             NaN           NaN      NaN  \n",
    "5        14.27057      -2.29566  0.00000  \n",
    "6        13.42293       6.86026  0.50000  \n",
    "7        16.60255       4.68752  0.33333  \n",
    "8             NaN           NaN      NaN  \n",
    "9         2.30485      -6.73367  0.00000  \n",
    "10       -7.95942      -3.23226  0.50000  \n",
    "11       -4.29258      -8.20323  0.33333  \n",
    "12       -5.03189      -2.51522  0.50000  \n",
    "13            NaN           NaN      NaN  \n",
    "14       -5.62638      -2.59159  1.00000  \n",
    "15        0.33659      13.16336  1.00000  \n",
    "16       -0.57178      10.26290  1.00000  \n",
    "17        2.37803       7.85893  0.75000  \n",
    "18        2.68629       9.02187  0.80000  \n",
    "19        4.37327       7.30692  0.66667  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_inputs_ex5"
    ]
   },
   "outputs": [],
   "source": [
    "### define demo inputs\n",
    "from tester_fw.test_utils import dfs_to_conn\n",
    "demo_conn_dfs_ex5 = {}\n",
    "demo_conn_dfs_ex5['PaceAdjustedCentered'] = pd.read_sql('select * from PaceAdjustedCenteredSample', conn).sort_values(['Season', 'TeamID', 'DayNum'])\n",
    "demo_conn_ex5 = dfs_to_conn(demo_conn_dfs_ex5)\n",
    "# display(demo_conn_dfs_ex5['PaceAdjustedCentered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex5"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Won  Season  DayNum  TeamID  OppID  Home      Pos    OppPos  \\\n",
      "0     0    2012      17    1108   1452     0      NaN       NaN   \n",
      "1     0    2012      25    1108   1408     0  8.25697   8.53697   \n",
      "2     0    2012      26    1108   1360     0  5.65314   5.93314   \n",
      "3     1    2012     105    1108   1115     1  2.76368   2.09702   \n",
      "4     0    2012      16    1355   1208     0      NaN       NaN   \n",
      "5     1    2012      31    1355   1237     0 -5.81233  -5.33233   \n",
      "6     0    2012      45    1355   1315     0  5.07403   4.81403   \n",
      "7     1    2012     124    1355   1237     0  4.12049   4.84049   \n",
      "8     0    2012      29    1431   1332     0      NaN       NaN   \n",
      "9     1    2012      52    1431   1155     0 -4.58353  -5.26353   \n",
      "10    0    2012      72    1431   1409     0 -5.65785  -7.11785   \n",
      "11    1    2012      79    1431   1187     1 -6.81332  -8.17332   \n",
      "12    1    2012     103    1431   1408     1 -6.71588  -7.96588   \n",
      "13    1    2017      47    1252   1399     0      NaN       NaN   \n",
      "14    1    2017      50    1252   1122     0  9.78901  10.22901   \n",
      "15    1    2017      68    1252   1244     1  7.09400   8.63400   \n",
      "16    0    2017      82    1252   1316     0  6.62264   8.36930   \n",
      "17    1    2017      86    1252   1367     1  7.55313   8.32313   \n",
      "18    0    2017     108    1252   1316     1  6.32893   6.93693   \n",
      "19    0    2017     122    1252   1316     1  6.91365   7.39365   \n",
      "\n",
      "    PtsAgstPer100  PtsForPer100   WinPct  \n",
      "0             NaN           NaN      NaN  \n",
      "1        26.44115     -18.48766  0.00000  \n",
      "2        21.51181     -30.28407  0.00000  \n",
      "3        16.34005     -20.09929  0.00000  \n",
      "4             NaN           NaN      NaN  \n",
      "5        14.27057      -2.29566  0.00000  \n",
      "6        13.42293       6.86026  0.50000  \n",
      "7        16.60255       4.68752  0.33333  \n",
      "8             NaN           NaN      NaN  \n",
      "9         2.30485      -6.73367  0.00000  \n",
      "10       -7.95942      -3.23226  0.50000  \n",
      "11       -4.29258      -8.20323  0.33333  \n",
      "12       -5.03189      -2.51522  0.50000  \n",
      "13            NaN           NaN      NaN  \n",
      "14       -5.62638      -2.59159  1.00000  \n",
      "15        0.33659      13.16336  1.00000  \n",
      "16       -0.57178      10.26290  1.00000  \n",
      "17        2.37803       7.85893  0.75000  \n",
      "18        2.68629       9.02187  0.80000  \n",
      "19        4.37327       7.30692  0.66667  \n"
     ]
    }
   ],
   "source": [
    "### call demo funtion\n",
    "print(get_team_stats(demo_conn_ex5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 5. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex5",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex5\n",
    "from tester_fw.testers import Tester_ex5\n",
    "tester = Tester_ex5()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_team_stats)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 6 - (3 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex6"
    ]
   },
   "source": [
    "<!-- Exercise text block -->\n",
    "Up to this point we have calculated our metrics for each team before they play each game. We're almost ready to start modeling! There is still one last task. Remember that there were two records in `PaceAdjusted` for each game. This is also true of `LaggedTeamStats`, which is a running average of that table. If \"Team A\" and \"Team B\" played a game on in some `Season` on some `DayNum` then there will be one record where \"Team A\" is the primary team and \"Team B\" is the opponent team and one record where \"Team B\" is the pirmary team and \"Team A\" is the opponent team. We need to join these records together so that we will have one record identifying each game.  \n",
    "\n",
    "Complete the function `get_matchup_stats(conn)` to query the `LaggedTeamStats` table using the db connection `conn` and return a Pandas DataFrame with the following columns:\n",
    "\n",
    "|Column Name|dtype|description|\n",
    "|-|-|-|\n",
    "|Won    |              int64|1 if primary team (`_x` suffix) won the matchup 0 otherwise|\n",
    "|Season    |           int64||\n",
    "|DayNum  |             int64||\n",
    "|TeamID   |            int64|Primary team - associated with `_x` suffixes |\n",
    "|OppID     |           int64|Opponent team - associated with `_y` suffixes|\n",
    "|Home_x      |         int64|Stats associated with primary team|\n",
    "|Pos_x         |     float64|Stats associated with primary team|\n",
    "|OppPos_x        |   float64|Stats associated with primary team|\n",
    "|PtsAgstPer100_x  |  float64|Stats associated with primary team|\n",
    "|PtsForPer100_x |    float64|Stats associated with primary team|\n",
    "|WinPct_x   |        float64|Stats associated with primary team|\n",
    "|Home_y     |          int64|Stats associated with opponent team|\n",
    "|Pos_y        |      float64|Stats associated with opponent team|\n",
    "|OppPos_y      |     float64|Stats associated with opponent team|\n",
    "|PtsAgstPer100_y  |  float64|Stats associated with opponent team|\n",
    "|PtsForPer100_y   |  float64|Stats associated with opponent team|\n",
    "|WinPct_y      |     float64|Stats associated with opponent team|\n",
    "\n",
    "**Notes:**\n",
    "- The columns should be in the **exact** order given above, but the records can be sorted any way you like.\n",
    "- The `dtypes` attribute of your result must match **exactly**.\n",
    "- This question can be answered using either SQL or Pandas. Pandas will give the required suffixes by default though.\n",
    "\n",
    "**Implementation Strategy**\n",
    "- You should start by joining/merging `LaggedTeamStats` to itself where the `OppID` in the left table is the same as the `TeamID` in the right table. The `Season` and `DayNum` should be the same for both tables.\n",
    "- After joining/merging:\n",
    "  - Remove any rows where the \"left\" `TeamID` is larger than the \"left\" `OppID`. This will avoid duplicating the data.\n",
    "  - Rows occurring before `DayNum` 56 should not be included in the result to make sure there is a reasonable sample of games so that the stats are meaningful.\n",
    "  - Drop any unnecessary columns.\n",
    "  - Rename the columns as necessary to meet the requirements above.\n",
    "  - Any rows containing `NULL` or `NaN` values should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true,
    "tags": [
     "exercise_solution_ex6"
    ]
   },
   "outputs": [],
   "source": [
    "### Define get_matchup_stats\n",
    "def get_matchup_stats(conn):\n",
    "\n",
    "    query = '''\n",
    "    SELECT a.Won, a.Season, a.DayNum, a.TeamID as TeamID_x, a.OppID as OppID_x, a.Home as Home_x, a.Pos as Pos_x, a.OppPos as OppPos_x, \n",
    "           a.PtsAgstPer100 as PtsAgstPer100_x, a.PtsForPer100 as PtsForPer100_x, a.WinPct as WinPct_x, \n",
    "           b.Home as Home_y, b.Pos as Pos_y, b.OppPos as OppPos_y, b.PtsAgstPer100 as PtsAgstPer100_y,\n",
    "           b.PtsForPer100 as PtsForPer100_y, b.WinPct as WinPct_y\n",
    "    FROM LaggedTeamStats a\n",
    "    JOIN LaggedTeamStats b\n",
    "    ON a.Season = b.Season AND a.DayNum = b.DayNum AND a.OppID = b.TeamID\n",
    "    WHERE a.TeamID < a.OppID AND a.DayNum >= 56\n",
    "    '''\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    df = df.rename(columns={'TeamID_x': 'TeamID', 'OppID_x': 'OppID'})\n",
    "\n",
    "    df = df.dropna()\n",
    " \n",
    "    return df\n",
    "\n",
    "\n",
    "#     df = pd.read_sql('select * from laggedteamstats', conn)\n",
    "#     return df.merge(df,\n",
    "#                    left_on=['Season', 'DayNum', 'OppID'],\n",
    "#                    right_on=['Season', 'DayNum', 'TeamID'])\\\n",
    "#                 .query('TeamID_x < OppID_x')\\\n",
    "#                 .query('DayNum >= 56')\\\n",
    "#                 .drop(columns=['Won_y', 'TeamID_y', 'OppID_y'])\\\n",
    "#                 .rename(columns={'Won_x':'Won', 'TeamID_x':'TeamID', 'OppID_x':'OppID'})\\\n",
    "#                 .dropna()\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex6"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "   Won  Season  DayNum  TeamID  OppID  Home_x    Pos_x  OppPos_x  \\\n",
    "2    1    2019      78    1210   1323       1 -0.90244  -1.03355   \n",
    "4    1    2011      72    1253   1413       1  2.31956   1.98356   \n",
    "\n",
    "   PtsAgstPer100_x  PtsForPer100_x  WinPct_x  Home_y    Pos_y  OppPos_y  \\\n",
    "2        -11.59260        -3.70151   0.55556       0 -2.65178  -2.09178   \n",
    "4          4.31931        -0.18928   0.46667       0 -2.84824  -2.20252   \n",
    "\n",
    "   PtsAgstPer100_y  PtsForPer100_y  WinPct_y  \n",
    "2         -2.28041         6.55518   0.61111  \n",
    "4          3.37227        -0.80974   0.28571 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_inputs_ex6"
    ]
   },
   "outputs": [],
   "source": [
    "### define demo inputs\n",
    "from tester_fw.test_utils import dfs_to_conn\n",
    "demo_conn_dfs_ex6 = {}\n",
    "demo_conn_dfs_ex6['LaggedTeamStats'] = pd.read_sql('select * from LaggedTeamStatsSample', conn)\n",
    "demo_conn_ex6 = dfs_to_conn(demo_conn_dfs_ex6)\n",
    "# display(pd.read_sql('select * from LaggedTeamStats', demo_conn_ex6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex6"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Won  Season  DayNum  TeamID  OppID  Home_x    Pos_x  OppPos_x  \\\n",
      "0    1    2019      78    1210   1323       1 -0.90244  -1.03355   \n",
      "1    1    2011      72    1253   1413       1  2.31956   1.98356   \n",
      "\n",
      "   PtsAgstPer100_x  PtsForPer100_x  WinPct_x  Home_y    Pos_y  OppPos_y  \\\n",
      "0        -11.59260        -3.70151   0.55556       0 -2.65178  -2.09178   \n",
      "1          4.31931        -0.18928   0.46667       0 -2.84824  -2.20252   \n",
      "\n",
      "   PtsAgstPer100_y  PtsForPer100_y  WinPct_y  \n",
      "0         -2.28041         6.55518   0.61111  \n",
      "1          3.37227        -0.80974   0.28571  \n"
     ]
    }
   ],
   "source": [
    "### call demo funtion\n",
    "print(get_matchup_stats(demo_conn_ex6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 6. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex6",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex6\n",
    "from tester_fw.testers import Tester_ex6\n",
    "tester = Tester_ex6()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_matchup_stats)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Aside - Random Forest classification model\n",
    "**Feel free to skip to the next exercise.**\n",
    "\n",
    "Logistic regression relies on a few assumptions about the predictive variables which are not met here (namely normality and each one individually having a significant effect on the response variable). Instead, we will use the off the shelf Scikit-Learn modules to implement the random forest modeling technique. We're building the model for you, but you will have to do some analysis of the predictions it makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log-Loss:\t\t0.5674 - 0 is perfect and 0.693 is considered \"non-informative\".\n",
      "Area under ROC curve:\t0.7775 - 1 is perfect and 0.5 is considered \"non-informative\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "### Example code showing how we got X and Y from the output of `get_matchup_stats` \n",
    "\n",
    "# stats_df = get_matchup_stats(conn)\n",
    "# # Horizontally partition our stats into predictive (we hope!) variables and the response variable\n",
    "# X = stats_df.drop(columns=['Won', 'Season', 'DayNum', 'TeamID', 'OppID']) # Remove the response and identification data\n",
    "# y = stats_df['Won'] # response variable. There are two classes, 0 and 1, which correspond to a loss and a win for the primary team.\n",
    "\n",
    "# load pre-computed X and y\n",
    "with open('resource/asnlib/publicdata/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('resource/asnlib/publicdata/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "\n",
    "# Vertically partition data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, random_state=6040)\n",
    "\n",
    "# Check to see if we already saved the model\n",
    "if not os.path.exists('resource/asnlib/publicdata/clf.pkl'): # if not - train and save the model\n",
    "    clf = GridSearchCV(RandomForestClassifier(),\n",
    "        scoring='roc_auc',\n",
    "        param_grid={\n",
    "            'max_depth': [2,4,6,8,9,10]\n",
    "        },\n",
    "        n_jobs=-1,\n",
    "        verbose=2).fit(X_train,y_train)\n",
    "    with open('resource/asnlib/publicdata/clf.pkl', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "# open the saved model from a pickle file\n",
    "with open('resource/asnlib/publicdata/clf.pkl', 'rb') as f:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        clf = pickle.load(f)\n",
    "\n",
    "# this is how you predict the probability that the response variable belongs to each class\n",
    "# probs[:, 0] is the estimated probabilites of losing and probs[:, 1] is the estimated probabilities of winning.\n",
    "probs = clf.predict_proba(X_test) \n",
    "\n",
    "# this is how you predict which class each record belongs to\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "# printing some metrics about how well the model fits the test set\n",
    "print(f'''\n",
    "Log-Loss:\\t\\t{round(log_loss(y_test, probs),4)} - 0 is perfect and 0.693 is considered \"non-informative\".\n",
    "Area under ROC curve:\\t{round(roc_auc_score(y_test, probs[:, 1]),4)} - 1 is perfect and 0.5 is considered \"non-informative\".\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 7 - (1 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex7"
    ]
   },
   "source": [
    "<!-- Exercise text block -->\n",
    "Without advanced statistical training, these fit metrics would probably not make sense. We see that they are both somewhere in between \"perfect\" and \"non-informative\", but what is that telling us? One understandable metric we can calculate is the prediction accuracy.\n",
    "\n",
    "Complete the function `pred_accuracy(obs, preds)` to calculate the relative frequency $\\left (\\frac{\\# matches}{\\# observations} \\right )$ that the predicted value `preds` is the same as the ovserved value `obs`. You can assume that both will be array-like, 1-dimensional, the same length and that they only contain the integers 0 and 1. Round your result to 5 decimal places.\n",
    "\n",
    "**Note:** There will be no type check. If your number matches our number you will pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    },
    "tags": [
     "exercise_solution_ex7"
    ]
   },
   "outputs": [],
   "source": [
    "### Define pred_accuracy\n",
    "def pred_accuracy(obs, preds):\n",
    "    \n",
    "    count = 0\n",
    "    for o, p in zip(obs, preds):\n",
    "        if o == p:\n",
    "            count +=1\n",
    "            \n",
    "    return round(count/len(obs), 5)\n",
    "\n",
    "\n",
    "    #return round(np.mean(obs==preds), 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex7"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "0.53333\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_inputs_ex7"
    ]
   },
   "outputs": [],
   "source": [
    "### define demo inputs\n",
    "rng = np.random.default_rng(6040)\n",
    "demo_obs_ex7 = rng.integers(0, 2, 15)\n",
    "demo_preds_ex7 = rng.integers(0, 2, 15)\n",
    "# print('obs:  ', demo_obs_ex7)\n",
    "# print('preds:', demo_preds_ex7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex7"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53333"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### call demo funtion\n",
    "pred_accuracy(demo_obs_ex7, demo_preds_ex7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 7. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex7",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex7\n",
    "from tester_fw.testers import Tester_ex7\n",
    "tester = Tester_ex7()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(pred_accuracy)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 8 - (2 Points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text_ex8"
    ]
   },
   "source": [
    "<!-- Exercise text block -->\n",
    "Another way to evaluate our model is to check how accuracy of the probabilities it generates. Suppose you have a list of the observations `obs` (0's and 1's indicating whether the primary team wins (1) or not(0)) and a list of the predicted probability `probs` that the primary team won for each observation. We can bucket the predictions based on the probabilities and then calculate the accuracy of our model within that bucket by taking the mean of the observations. If the observed win % for each bucket is between or close to its bounds, we have a decent model.\n",
    "\n",
    "Complete the function `bucket_evaluation(obs, prob, n_buckets)` to partition the interval $[0, 1)$ into `n_buckets` equal intervals and compute the observed relative win percentage for the events in that bucket. You should return your result as a Pandas DataFrame with the following columns:\n",
    "\n",
    "|Column Name|dtype|description|Special Considerations|\n",
    "|-|-|-|-|\n",
    "|lower|          float64 | lower bound of bucket | round to 2 decimal places|\n",
    "|upper|          float64 | upper bound of bucket | round to 2 decimal places|\n",
    "|obs_win_pct|    float64 | win % for observations where lower $\\le$ estimated win probability < upper | round to 2 decimal places (as a percent)|\n",
    "|n|              int64   | number of observations where lower $\\le$ estimated win probability < upper | |\n",
    "\n",
    "**Notes:**\n",
    "- The columns should be in the **exact** order given above, **and the records should be sorted with the `'lower'` column in ascending order and a reset index**.\n",
    "- The `dtypes` attribute of your result must match **exactly**.\n",
    "- The bounds should be rounded **before** deciding which bucket each observation belongs in.\n",
    "- **The \"obs_win_pct\" column should have `NaN` entries for any \"empty\" buckets which have no observations.**\n",
    "  - Your solution raising a warning will not cause it to fail the test cell.\n",
    "\n",
    "**Implementation Strategy**\n",
    "- `np.linspace()` can be helpful for calculating the bounds for each bucket. **Don't forget to round!**\n",
    "- The function `zip(bounds[:-1], bounds[1:]` can be iterated over to sequentially examine each pair of bounds (`bounds` would be the output of `linspace` after rounding).\n",
    "  - Use each pair of bounds to filter the `obs` to only include observations where the `prob` is between the lower and upper bounds. You can calculate the observed relative frequency and count from the filtered results.\n",
    "  - Keep track of the endpoints, relative frequency, and count for each interval.\n",
    "- After evaluating for all intervals, construct a DataFrame using the stored results for each interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true,
    "tags": [
     "exercise_solution_ex8"
    ]
   },
   "outputs": [],
   "source": [
    "### Define bucket_evaluation\n",
    "def bucket_evaluation(obs, prob, n_buckets):\n",
    "    \n",
    "    bounds = np.linspace(0, 1, n_buckets+1)\n",
    "    bounds = np.round(bounds, 2)\n",
    "    \n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "    obs_win_pcts = []\n",
    "    n_obs = []\n",
    "\n",
    "    for lower, upper in zip(bounds[:-1], bounds[1:]):\n",
    "  \n",
    "        obs_in_range = [o for o, p in zip(obs, prob) if lower <= p < upper]\n",
    "        \n",
    "        n = len(obs_in_range)\n",
    "        \n",
    "        filtered_list = list(filter(lambda x: x == 1, obs_in_range)) \n",
    "        count = len(filtered_list)\n",
    "        \n",
    "        if len(obs_in_range) == 0:\n",
    "            obs_win_pct = np.nan\n",
    "        else:      \n",
    "            obs_win_pct = np.round((count/n)*100, 2)\n",
    "            \n",
    "        lower_bounds.append(lower)\n",
    "        upper_bounds.append(upper)\n",
    "        obs_win_pcts.append(obs_win_pct)\n",
    "        n_obs.append(n)\n",
    "    \n",
    "    result_df = pd.DataFrame({'lower': lower_bounds, 'upper': upper_bounds, 'obs_win_pct': obs_win_pcts, 'n': n_obs})\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "    bounds = np.round(np.linspace(0,1, n_buckets+1),2)\n",
    "    lod = []\n",
    "    for lower, upper in zip(bounds[:-1], bounds[1:]):\n",
    "        inds = np.argwhere((prob >= lower) & (prob < upper)).reshape((-1,))\n",
    "        n = inds.shape[0]\n",
    "        win_pct = 100*np.mean(obs[inds])\n",
    "        d = {'lower': lower, 'upper': upper, 'obs_win_pct': win_pct, 'n': n}\n",
    "        lod.append(d)\n",
    "    return pd.DataFrame(lod).apply(lambda f: round(f, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md_ex8"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo cell below should display the following output:\n",
    "```\n",
    "   lower  upper  obs_win_pct   n\n",
    "0   0.00   0.25        25.00   4\n",
    "1   0.25   0.50        23.08  13\n",
    "2   0.50   0.75        66.67   3\n",
    "3   0.75   1.00        40.00   5\n",
    "```\n",
    "**Unlike previous exercises the order and index must match (in addition to the usual requirements) to produce an easily understood result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_inputs_ex8"
    ]
   },
   "outputs": [],
   "source": [
    "### define demo inputs\n",
    "rng = np.random.default_rng(6040)\n",
    "demo_obs_ex8 = rng.integers(0, 2, 25)\n",
    "demo_prob_ex8 = rng.random(25)\n",
    "demo_n_buckets_ex8 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_run_ex8"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lower  upper  obs_win_pct   n\n",
      "0   0.00   0.25        25.00   4\n",
      "1   0.25   0.50        23.08  13\n",
      "2   0.50   0.75        66.67   3\n",
      "3   0.75   1.00        40.00   5\n"
     ]
    }
   ],
   "source": [
    "### call demo funtion\n",
    "print(bucket_evaluation(demo_obs_ex8, demo_prob_ex8, demo_n_buckets_ex8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 8. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex8",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing tester_fw.tester_6040\n",
      "Passed! Please submit.\n"
     ]
    }
   ],
   "source": [
    "### test_cell_ex8\n",
    "from tester_fw.testers import Tester_ex8\n",
    "tester = Tester_ex8()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(bucket_evaluation)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Fin.** If you have made it this far, congratulations on completing the semester. **Don't forget to submit!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2b38b6e01547e8f771d473ea2b8718fd0728eea782e4c924ed8783f739d4a6c"
  },
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
